# Kaggle ML Models & Experimental Insights

---

This repository is my central hub for machine learning models and experimental design approaches developed for Kaggle activities and personal projects. I designed it to store and organize my diverse collection of solutions, predictive models, and strategies for understanding causal relationships across various problem types.

Whether I'm looking back at past work, learning new techniques, or simply sharing my creations, this repository aims to be a comprehensive resource showcasing my practical machine learning applications and my commitment to data-driven causal inference.

---

### Common Machine Learning Models I Use

Here's a concise list of frequently used machine learning models you'll often find in my work:

* **Supervised Learning:**
    * **For predicting continuous values (Regression):** Linear Regression, Ridge/Lasso Regression, Support Vector Regression (SVR), Decision Trees, Random Forests, Gradient Boosting Machines (like XGBoost, LightGBM), K-Nearest Neighbors (KNN).
    * **For predicting categories (Classification):** Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Decision Trees, Random Forests, Gradient Boosting Machines (XGBoost, LightGBM), Naive Bayes.

* **Unsupervised Learning:**
    * **For grouping similar data (Clustering):** K-Means, Hierarchical Clustering, DBSCAN, Gaussian Mixture Models (GMM).
    * **For reducing the number of features (Dimensionality Reduction):** Principal Component Analysis (PCA), t-SNE, UMAP.

* **Ensemble Methods:**
    * **Bagging:** Like **Random Forest**, where multiple models are trained independently.
    * **Boosting:** Such as **AdaBoost** and **Gradient Boosting** (including XGBoost), where models are built sequentially, correcting previous errors.
    * **Stacking:** Combines predictions from diverse models using a "meta-model."

---

### Experimental Design & A/B Testing in Kaggle

Beyond just building predictive models, I also leverage Kaggle as a platform to practice and apply principles of **experimental design**, particularly **A/B testing**. Understanding causality and evaluating the true impact of interventions is crucial in many data science applications.

In my Kaggle work, this involves:

* **Simulating A/B Tests:** Utilizing datasets to create hypothetical control and treatment groups, then analyzing the simulated outcomes to understand the statistical significance of different "interventions."
* **Analyzing Quasi-Experimental Data:** Applying statistical methods to draw causal inferences from observational data where true randomization may not have occurred.
* **Hypothesis Testing:** Formulating clear hypotheses, designing tests to validate them, and interpreting p-values and confidence intervals to make data-driven decisions.
* **Metric Selection & Power Analysis:** Carefully choosing appropriate metrics for evaluating experimental outcomes and considering statistical power to ensure reliable results.
* **Interpreting Results:** Drawing actionable insights from experimental data, understanding limitations, and communicating findings effectively.

This focus allows me to not only build accurate predictive models but also to assess their real-world impact and contribute to robust, evidence-based decision-making.
